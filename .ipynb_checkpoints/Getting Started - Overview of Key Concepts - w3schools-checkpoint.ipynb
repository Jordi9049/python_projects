{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING STARTED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analysing/Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "#pandas and numpy are the libraries, pd and np are simply references to those libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#opening the file - df is a common variable name used for holding data extracted from a data file - abbreviated form of DataFrame\n",
    "#you can name your DataFrame anything you like\n",
    "#if this ipynb document has been created in the same location as your data file, you should be able to access the file as follows\n",
    "df = pd.read_csv('dirtydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view the DataFrame type df - if there are too many records it will not display them all\n",
    "  #if it is a small DataFrame like this one, the entire contents will be displayed\n",
    "  #if it is an extremely large DataFrame you will only see some of the top rows and bottoms rows\n",
    "  #Notice the indexing on the left is in bold - these are row references to make it easier for you to access data \n",
    "    # - they start at 0\n",
    "  #At this point they are not actually part of your dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important observations from the dataset above**  \n",
    "  \n",
    "From this simple command we can make several interesting observations about our data\n",
    "\n",
    "The data set contains some empty cells (\"Date\" in row 22, and \"Calories\" in row 18 and 28).\n",
    "\n",
    "The data set contains data that is in the wrong format (\"Date\" in row 26).\n",
    "\n",
    "The data set contains incorrect data (\"Duration\" in row 7).\n",
    "\n",
    "The data set contains duplicates (row 11 and 12).\n",
    "\n",
    "**Remember** - your datasets will not always be this short, so you may not be able to 'see' potential issues. We will need to use other techniques to determine issues with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the shape of the data - the number of rows and the number of columns\n",
    "#32 rows and 5 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the column headings\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the data types - Python needs to work on numerical data only. \n",
    "  #We can see here that one of our columns has a type Object\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code lets you have a look at the top 5 rows of the table\n",
    "  #you can specify a number of rows to display - simply type the number of rows in the brackets\n",
    "  #the column on the left (without a heading) is an index reference to each row. It does not exist in the actual data file.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the last 5 rows of the dataframe - do a google search for 'pandas view the last n rows in dataframe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code provides lots of useful information about the data - \n",
    "  #for example, you can see that the Calories column has 2 missing values\n",
    "  #by default this just describes the numerical data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can explicitly specify numerical information - it will produce the same output as the cell above\n",
    "df.describe(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can also retrieve information about the Object data - here you can see that we are missing a Date value\n",
    "df.describe(include = \"O\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have a large dataset you will have to use code to check for null values\n",
    "  #This code will count the Null values in each column\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a google search to see if there are any other ways to count null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will count the Null values in each row\n",
    "df.isnull().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you simply want to drop any rows that contain null values use dropna\n",
    "\n",
    "#for demonstration purposes read in a fresh copy of the data file to a new temporary DataFrame \n",
    "  #Our original df will not be changed\n",
    "temp_df = pd.read_csv('dirtydata.csv')\n",
    "\n",
    "#drop null values in the DataFrame\n",
    "temp_df = df.dropna()\n",
    "\n",
    "#Check the shape of the DataFrame after dropping rows with null values\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows 18 and 28 in the dataset have null values in the Calories column - algorithms cannot handle null values\n",
    "  #rather than simply drop rows and potentially lose other valuable data, \n",
    "  #data scientists employ various techniques to handle missing values\n",
    "#if you want to replace null values in a specific column with a specfic value\n",
    "    #using inplace=True will implement the change in the dataframe - you do not have to SAVE this change.\n",
    "\n",
    "#to test this read in a fresh copy of your data file\n",
    "temp_df = pd.read_csv('dirtydata.csv')\n",
    "\n",
    "#replace null values in the Calories column with a specific value\n",
    "temp_df['Calories'].fillna(130, inplace = True)\n",
    "\n",
    "#display temp_df\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the Null values in each column again to see that the Calories column no longer contains null values\n",
    "temp_df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or display the contents of temp_df to check rows 18 and 28\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You could also display the contents of just one column in the DataFrame\n",
    "#When accessing columns in your code:\n",
    "  #make sure the name is in single quotes and matches the exact spelling of the column name in the dataset\n",
    "temp_df['Calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way of accessing a single column is as follows:\n",
    "temp_df.Calories\n",
    "  #NOTE:This technique will not work if your column name has a space in it - brackets and speech marks always work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is more common to use either mean, medium or mode to fill in a missing value\n",
    "\n",
    "#MEAN\n",
    "#to test this read in a fresh copy of your data file\n",
    "temp_df = pd.read_csv('dirtydata.csv')\n",
    "\n",
    "#calculate the mean of the calories column - 304.68\n",
    "x = temp_df['Calories'].mean()\n",
    "\n",
    "#Print the value of x - just so you can see it\n",
    "#print(x)\n",
    "\n",
    "#If you want to print the contents of a variable that holds a numeric value and some text, \n",
    "  #you need to cast your numeric value to a string \n",
    "print(\"Mean:\" + str(x))\n",
    "\n",
    "#Use x to fill null values\n",
    "temp_df['Calories'].fillna(x, inplace = True)\n",
    "\n",
    "#display temp_df to check rows 18 and 28\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEDIAN\n",
    "#to test this read in a fresh copy of your data file\n",
    "temp_df = pd.read_csv('dirtydata.csv')\n",
    "\n",
    "#calculate the median of the Calories column - 291.2\n",
    "x = temp_df['Calories'].median()\n",
    "print(\"Median:\" + str(x))\n",
    "\n",
    "#Use x to fill null values\n",
    "temp_df['Calories'].fillna(x, inplace = True)\n",
    "#display temp_df - check rows 18 and 28\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODE\n",
    "#to test this read in a fresh copy of your data file\n",
    "temp_df = pd.read_csv('dirtydata.csv')\n",
    "\n",
    "#calculate the mode of the Calories column - 300.0\n",
    "x = temp_df['Calories'].mode()[0]\n",
    "print(\"Mode:\" + str(x))\n",
    "\n",
    "#Use x to fill null values\n",
    "temp_df['Calories'].fillna(x, inplace = True)\n",
    "#display temp_df - check rows 18 and 28\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAX - to calculate this use max()\n",
    "\n",
    "#read in a fresh copy of your data file to temp_df\n",
    "temp_df = pd.read_csv('dirtydata.csv')\n",
    "\n",
    "#calculate the maximum value of the Calories column - 479.0\n",
    "\n",
    "#print the maximum value\n",
    "\n",
    "\n",
    "#Use the maximum value to fill null values\n",
    "\n",
    "#display temp_df - check rows 18 and 28\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIN - to calculate this use min()\n",
    "\n",
    "#read in a fresh copy of your data file to temp_df\n",
    "temp_df = pd.read_csv('dirtydata.csv')\n",
    "\n",
    "#calculate the minimum value in the Calories column - 195.1\n",
    "\n",
    "#print the minimum value\n",
    "\n",
    "#Use the minimum value to fill null values\n",
    "\n",
    "#display temp_df - check rows 18 and 28\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose either mean, median, mode, max or min \n",
    "  #and replace the null values in the Calories column of our original dataframe - df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Date Issues - Nulls & Date Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the original dataframe\n",
    "  #if we look at the Date column we can see an issue in row 22 and row 26\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we run the following code it will attempt to format the fields as dates\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data types in the dataframe again and you will notice that date no longer has a type Object\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the data above we can see the issue with the date in row 26 was resolved\n",
    "#the result in the example above gave us a NaT value in row 22, which can be handled as a NULL value\n",
    "#we can remove the row by using the dropna() method. \n",
    "#Rather than just drop all rows with null values - we can explicity state to drop rows where there is a null value in Date\n",
    "    #This would mean that other null values would not be deleted\n",
    "    \n",
    "df.dropna(subset=['Date'], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Wrong Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Wrong data\" does not have to be \"empty cells\" or \"wrong format\", \n",
    "#it can just be wrong, like if someone registered \"199\" instead of \"1.99\"\n",
    "#The duration value in row 7 is evidently wrong\n",
    "\n",
    "#We could change the value in the field with a specific value, as follows:\n",
    "df.loc[7,'Duration'] = 45\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now change it back so we can try something else\n",
    "df.loc[7,'Duration'] = 450\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the data set it too large it would not be possible to manually locate errors\n",
    "  #If we wanted to check which rows in a particular column contain incorrect data,\n",
    "  #we could loop through all values in that column\n",
    "\n",
    "#loop through all values in the \"Duration\" column.\n",
    "  #if the value is higher than 120, print the row number and the value:\n",
    "for x in df.index:\n",
    "  if df.loc[x, 'Duration'] > 120:\n",
    "    #print the row and value - just so we can see where they are\n",
    "    print(x ,df.loc[x, 'Duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the value is higher than 120, set it to 120\n",
    "\n",
    "for x in df.index:\n",
    "  if df.loc[x, 'Duration'] > 120:\n",
    "    df.loc[x, 'Duration'] = 120\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We could replace values with a mean value\n",
    "#reset the value again\n",
    "df.loc[7,'Duration'] = 450\n",
    "\n",
    "#calculate the mean value of the duration column - 69.19354838709677\n",
    "m= df['Duration'].mean()\n",
    "\n",
    "#You could round the result is you needed to - try this\n",
    "#m = round(m, 0)\n",
    "\n",
    "#loop through all values in the \"Duration\" column.\n",
    "#if the value is higher than 120, set it to m (the mean):\n",
    "for x in df.index:\n",
    "  if df.loc[x, 'Duration'] > 120:\n",
    "    df.loc[x, 'Duration'] = m\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternatively we could drop the row if it exceeds a certain value in a specified column\n",
    "#reset the value again\n",
    "df.loc[7,'Duration'] = 450\n",
    "\n",
    "for x in df.index:\n",
    "  if df.loc[x, 'Duration'] > 120:\n",
    "    df.drop(x, inplace = True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the dataframe above, rows 11 & 12 are duplicated\n",
    "\n",
    "#This code returns True for every row that is a duplicate, otherwise it returns False\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will drop duplicated rows\n",
    "df.drop_duplicates(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe as a new dataset.\n",
    "#Index = false is used to ensure that the row index values are not included in the dataset\n",
    "df.to_csv('cleandata.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
